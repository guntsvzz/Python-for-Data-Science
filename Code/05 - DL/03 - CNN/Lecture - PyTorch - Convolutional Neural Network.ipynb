{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## PyTorch - Convolutional Neural Network\n",
    "\n",
    "- [WEIDMAN] Ch7\n",
    "- https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last class we use linear network for classifying MNIST data.  Today we shall propose CNN (Convolutional Neural Network) as a better way for dealing with image classification.\n",
    "\n",
    "There are mainly three layers that can help dealing with images:\n",
    "\n",
    "1. Convolutional layer\n",
    "2. Max/Average pooling layer\n",
    "3. BatchNorm layer\n",
    "4. Dropout layer\n",
    "\n",
    "### 1. Convolutional Layer\n",
    "Let's say given a image of 14 x 14 pixels = 196 features like this.  Each data point is an array of numbers describing how dark each pixel is, where value range from 0 to 255.  These values can be normalized ranging from 0 to 1. For example, for the following digit (the digit 1), we could have:\n",
    "\n",
    "<img src =\"figures/one.png\" width=\"250\">\n",
    "\n",
    "It is first important to define the input shape of an image, which will be <code>(input channels, image height, image width)</code>.  If we have lots of images, the input shall be <code>(batch size, input channels, image height, image width)</code>.  For our case, if it is a grayscale image, the shape is <code>(1, 14, 14)</code>.  If it is a RGB image, it shall be <code>(3, 14, 14)</code>.  If it is a CMYK, it shall be <code>(4, 14, 14)</code>.  If I define batch size as 500 (out of many more images I have), my input is <code>(500, 4, 14, 14)</code>.  (Commonly, batch size is around few hundreds).\n",
    "\n",
    "Convolutional network works on the central concept of a convolution operation like this:\n",
    "\n",
    "<img src =\"figures/no_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "Mathematically, it looks like this:\n",
    "\n",
    "Let's say we have a 5 x 5 input image $I$ of channel 0 of batch 0:\n",
    "\n",
    "$$ I = \\begin{bmatrix}\n",
    "i_{11} & i_{12} & i_{13} & i_{14} & i_{15}\n",
    "\\\\\n",
    "i_{21} & i_{22} & i_{23} & i_{24} & i_{25}\n",
    "\\\\\n",
    "i_{31} & i_{32} & i_{33} & i_{34} & i_{35}\n",
    "\\\\\n",
    "i_{41} & i_{42} & i_{43} & i_{44} & i_{45}\n",
    "\\\\\n",
    "i_{51} & i_{52} & i_{53} & i_{54} & i_{55}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each of this pixel may represent the brightness ranging from 0 to 255.  Or if normalized, shall be 0 to 1.\n",
    "\n",
    "If we define a 3 x 3 patch which we commonly called **weights (W)** or in computer vision, we called **filters/kernels** like this (*we shall called filters in this lecture note for simplicity*) :\n",
    "\n",
    "$$ W = \\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13}\n",
    "\\\\\n",
    "w_{21} & w_{22} & w_{23}\n",
    "\\\\\n",
    "w_{31} & w_{32} & w_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let's say we are scanning the middle of the image, then the output feature would be (we'll denote this as $o_{33}$):\n",
    "\n",
    "$$o_{33} = w_{11} * i_{22} + w_{12} * i_{23} + w_{13} * i_{24} + \\\n",
    "           w_{21} * i_{32} + w_{22} * i_{32} + w_{23} * i_{34} + \\\n",
    "           w_{32} * i_{43} + w_{33} * i_{44}$$\n",
    "           \n",
    "This will result in one output feature called **feature map**.  Of course, we may add bias to it and then will be fed through an activation function.\n",
    "\n",
    "Actual feature maps look like this.  Each feature map is a output of a single training example and convolve each kernel over the sample.    In simple words, if we have $k$ filters, then we have $k$ feature maps.  They represent the activation part corresponding to the kernels.\n",
    "\n",
    "<img src =\"figures/feature-map2.png\" width=\"450\">\n",
    "\n",
    "In a convolution operation, there are 3 main hyperparameters to fine tune - (1) filter size, (2) padding, and (3) stride.\n",
    "\n",
    "#### A. Filters\n",
    "\n",
    "1. **How the filters look like?**.  It turns out that each filter actually detect the presence of certain visual pattern.  For example, this filter below detects whether there is an edge at that location of the image.  There are also other similar filters detecting corners, lines, etc.  Check out https://setosa.io/ev/image-kernels/  and try changing the values\n",
    "\n",
    "$$ w = \\begin{bmatrix}\n",
    "0 & 1 & 0\n",
    "\\\\\n",
    "1 & -4 & 1\n",
    "\\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Real filters can look like this.  They may look somewhat random at first glance, but we can see that clear structure being learned in most kernels. For example, filters 3 and 4 seem to be learning diagonal edges in opposite directions, and other capture round edges or enclosed spaces:\n",
    "\n",
    "<img src =\"figures/kernels.png\" width=\"200\">\n",
    "\n",
    "However, **it is important to note that we DON'T need to decide the filters** to use.  We can simply feed a random generated filter, and it is the job of CNN to learn these filters.   These learned filters will learn what features are most efficient for the classification process.\n",
    "\n",
    "**What is the shape of filters?**.  For each image, we can apply multiple filters, depending on how many output channels we want.  Let's say the input channel is 3, and we want the output channel to 64, then we apply a filter of size <code>(3, 64, filter width, filter height)</code>.  How do we know how many output channel to use? The answer is we don't know...we just try and see what works.  More filter allows the network to look at more patterns.\n",
    "\n",
    "**What should be the filter size?**  If we use a 3 x 3 filter, each pixel got 8 neighboring information.  On the other hand, if we we use big filter like 9 x 9, then we got 80 neighboring information.  Typical size is 3 and 5.\n",
    "\n",
    "\n",
    "#### B. Padding\n",
    "\n",
    "2. **How should we convolve the edges?**. Recall this image:\n",
    "\n",
    "<img src =\"figures/no_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "It has 4 x 4 pixels = 16 features.  But after convolution, we only got 2 x 2 pixels = 4 features left.  Is that good?  There are no correct answers here but we are quite sure that we lose some information.  One way is address this is **padding**, where we can enlarge the input image by padding the surroundings with zeros.  How much?  Padding until we get the original size or larger size, for example, like this.  The below put zero padding around which result the output features to be the same size as input features.\n",
    "\n",
    "<img src =\"figures/same_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "The below put even more padding which pad to make sure each single pixel is convoluted (full padding), which result the output features to be even large\n",
    "\n",
    "<img src =\"figures/full_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "#### C. Strides\n",
    "\n",
    "3. **How many step we should take to slide our filter? Skip 2?** Should we shift 1 step per convolution, or 2 steps, or how many steps.  **In fact, it really depends on how detail you want it to be.  But defining bigger steps reduce the feature size and thus reduce the computation time.**  Bigger step is like human scanning picture more roughly but can reduce the computation time....whether to use it is something to be experimented though. \n",
    "\n",
    "In computer vision, we called this step as **stride**.  Example is like this:\n",
    "\n",
    "**No padding with stride of 2**\n",
    "\n",
    "<img src =\"figures/no_padding_strides.gif\" width=\"150\">\n",
    "\n",
    "**Padding with stride of 2**\n",
    "\n",
    "<img src =\"figures/padding_strides.gif\" width=\"150\">\n",
    "\n",
    "Actual image convolution can look like this (with stride 1 and no padding):\n",
    "\n",
    "<img src =\"figures/conv.gif\" width=\"400\">\n",
    "\n",
    "The convoluted image may look like this (nothing relate with the above matrix though):\n",
    "\n",
    "<img src =\"figures/convimages.png\" width=\"400\">\n",
    "\n",
    "**The formula to be used to measure the padding value to get the spatial size of the input and output volume to be the same with stride 1** is\n",
    "\n",
    "$$ \\frac{K-1}{2} $$\n",
    "\n",
    "where $K$ is the filter size.\n",
    "\n",
    "This means that if our image is size $24 * 24$, and the filter size is $3 x 3$, then our $K$ has size 3 so the padding should be $(3-1)/2 = 1$, then we need to add **a border of one pixel valued 0 around the outside of the image**, which would result in the input image of size $26 * 26$\n",
    "\n",
    "#### D. Shape\n",
    "\n",
    "4. **What would be the shape of the output matrix?**\n",
    "\n",
    "The output shape (denote as $O$) depend on the stride (denote as $S$), padding (denote as $P$), filter size (denote as $F$) as well as the input width and height (denote as $I$). $O$ can be calculated with the formula as follows:\n",
    "\n",
    "$$O = \\frac{I-F+2P}{S} + 1$$\n",
    "\n",
    "In this case (code below), if our I is 28, F is 5, P is 2, and S is 1 then the width/height is 28\n",
    "\n",
    "In conclusion, \n",
    "\n",
    "- The input will have a 4D shape of <code>(batch size, input channels, input height, input width)</code>\n",
    "\n",
    "- The output will have a 4D shape of <code>(batch size, output channels, output height, output width)</code>\n",
    "\n",
    "- The convolutional filters will have 4D shape of <code>(input channels, output channels, filter height, filter width)</code>\n",
    "\n",
    "**Note: The order does not matter and it depends on the python library you use but these four dimensions always exist in CNN.**\n",
    "\n",
    "### 2. Max/Average Pooling Layer\n",
    "\n",
    "Talking about **reducing computation time**, a common way is to perform a **pooling layer** which simply downsample the image by average a set of pixels, or by taking the maximum value.  If we define a pooling size of 2, this involves mapping each 2 x 2 pixels to one output, like this:\n",
    "\n",
    "<img src =\"figures/pooling.png\" width=\"150\">\n",
    "\n",
    "Nevertheless, pooling has a really big downsides, i.e., it basically lose a lot of information.  Compared to strides, strides simply scan less but maintain the same resolution but pooling simply reduce the resolution of the images....As Geoffrey Hinton said on Reddit AMA in 2014 - **The pooling operation used in CNN is a big mistake and the fact that it works so well is a disaster**.  In fact, in most recent CNN architectures like ResNets, it uses pooling very minimially or not at all.\n",
    "\n",
    "### 3. BatchNorm Layer\n",
    "\n",
    "Batch norm is nothing other than normalize samples within the batch.  That is, minus the mean of features within the batch.  This helps with unstable gradients in SGD. Note that the output size does not change from input size after BatchNorm.\n",
    "\n",
    "<img src =\"figures/batchnorm.png\" width=\"300\">\n",
    "\n",
    "<img src =\"figures/landscape.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### 4. Dropout Layer\n",
    "\n",
    "This is a layer of arbitrarily removing some values in your data.  By randomly removing data in each iteration, you make the neural network more robust against overfitting, because it needs to learn to fight with incomplete data.\n",
    "\n",
    "For example, say we have a vector of $x = {1, 2, 3, 4, 5}$.  Let's set $p=0.2$ which means 20\\% of data will be turn to 0.  In training mode, $x_\\text{train} = {1, 0, 3, 4, 5}$ ; do not confuse why I turn off 2 and not others, I just turn 20\\% off randomly.  In evaluation mode, we turn off dropout, but to make sure the distribution remains similar, we multiply the values by $1 - 0.2 = 0.8$, which becomes $x_\\text{inference} = {0.8, 1.6, 2.4, 3.2, 4.0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.ryerson.ca/~aharley/vis/conv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ETL: Load the MNIST dataset\n",
    "PyTorch makes the MNIST train and test datasets available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. The first time they're called, the datasets will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # Pytorch transformation to tensor\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(train_data, [50000, 10000])\n",
    "\n",
    "test_data  = datasets.MNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "val_loader   = DataLoader(val_set, batch_size=10, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a convolutional model\n",
    "\n",
    "In the previous section we used only fully connected layers, with an input layer of 784 (our flattened 28x28 images), hidden layers of 120 and 84 neurons, and an output size representing 10 possible digits.\n",
    "\n",
    "This time we'll employ two convolutional layers and two pooling layers before feeding data through fully connected hidden layers to our output. The model follows CONV/RELU/POOL/CONV/RELU/POOL/FC/RELU/FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take.</strong><br>\n",
    "\n",
    "1. Extend the base Module class:\n",
    "   \n",
    "<tt><font color=black>class ConvolutionalNetwork(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the convolutional layers with <a href='https://pytorch.org/docs/stable/nn.html#conv2d'><tt><strong>torch.nn.Conv2d()</strong></tt></a><br><br>The first layer has one input channel (the grayscale color channel). We'll assign 6 output channels for feature extraction. We'll set our kernel size to 3 to make a 3x3 filter, and set the step size to 1.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv1 = nn.Conv2d(1, 6, 3, 1)</font></tt><br>\n",
    "The second layer will take our 6 input channels and deliver 16 output channels.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv2 = nn.Conv2d(6, 16, 3, 1)</font></tt><br><br>\n",
    "\n",
    "3. Set up the fully connected layers with <a href='https://pytorch.org/docs/stable/nn.html#linear'><tt><strong>torch.nn.Linear()</strong></tt></a>.<br><br>The input size of (5x5x16) is determined by the effect of our kernels on the input image size. A 3x3 filter applied to a 28x28 image leaves a 1-pixel edge on all four sides. In one layer the size changes from 28x28 to 26x26. We could address this with zero-padding, but since an MNIST image is mostly black at the edges, we should be safe ignoring these pixels. We'll apply the kernel twice, and apply pooling layers twice, so our resulting output will be \n",
    "$\\;(((28-2)/2)-2)/2 = 5.5\\;$ which rounds down to 5 pixels per side.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc1 = nn.Linear(5\\*5\\*16, 120)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc2 = nn.Linear(120, 84)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc3 = nn.Linear(84, 10)</font></tt><br>\n",
    "See below for a more detailed look at this step.<br><br>\n",
    "\n",
    "4. Define the forward method.<br><br>Activations can be applied to the convolutions in one line using <a href='https://pytorch.org/docs/stable/nn.html#id27'><tt><strong>F.relu()</strong></tt></a> and pooling is done using <a href='https://pytorch.org/docs/stable/nn.html#maxpool2d'><tt><strong>F.max_pool2d()</strong></tt></a><br>\n",
    "<tt><font color=black>def forward(self, X):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv2(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "</font></tt>Flatten the data for the fully connected layers:<br><tt><font color=black>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = X.view(-1, 5\\*5\\*16)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.fc1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = self.fc2(X)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return F.log_softmax(X, dim=1)</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the convolutional layers</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the first MNIST record\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break\n",
    "    \n",
    "X_train.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank-4 tensor to be passed into the model\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Run the first pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data\n",
    "x = x.view(-1, 5*5*16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the convolution output is passed into the fully connected layers.</strong></div>\n",
    "\n",
    "Now let's run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the bias terms for each layer, the total number of parameters being trained is:<br>\n",
    "\n",
    "$\\quad\\begin{align}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times120)+120+(120\\times84)+84+(84\\times10)+10 &=\\\\\n",
    "54+6+864+16+48000+120+10080+84+840+10 &= 60,074\\end{align}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 48000\n",
      "   120\n",
      " 10080\n",
      "    84\n",
      "   840\n",
      "    10\n",
      "______\n",
      " 60074\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
      "          [ 0.3062, -0.0730,  0.0673],\n",
      "          [-0.1623,  0.1958,  0.2938]]],\n",
      "\n",
      "\n",
      "        [[[-0.2445,  0.2897,  0.0624],\n",
      "          [ 0.2463,  0.0451,  0.1607],\n",
      "          [-0.0471,  0.2570,  0.0493]]],\n",
      "\n",
      "\n",
      "        [[[-0.1556,  0.0850, -0.1536],\n",
      "          [-0.0391, -0.1354,  0.2211],\n",
      "          [-0.2631, -0.1537, -0.0941]]],\n",
      "\n",
      "\n",
      "        [[[-0.2004,  0.0315, -0.3292],\n",
      "          [ 0.3010, -0.2832,  0.2573],\n",
      "          [ 0.0555, -0.1082,  0.2060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0520,  0.2693,  0.0364],\n",
      "          [-0.1051,  0.0896, -0.0904],\n",
      "          [ 0.1403,  0.2976,  0.1927]]],\n",
      "\n",
      "\n",
      "        [[[-0.1457,  0.1924,  0.0596],\n",
      "          [ 0.1693, -0.2032, -0.3300],\n",
      "          [-0.1288, -0.2557,  0.2735]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0960,  0.1381,  0.1054, -0.0058,  0.2609, -0.2368],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0086, -0.0929,  0.0420],\n",
      "          [-0.0469,  0.0417, -0.0284],\n",
      "          [ 0.1129, -0.0807, -0.0812]],\n",
      "\n",
      "         [[-0.0812,  0.1224,  0.0453],\n",
      "          [ 0.1309, -0.1123, -0.1350],\n",
      "          [-0.1065, -0.0915,  0.0551]],\n",
      "\n",
      "         [[ 0.0487,  0.1131, -0.0703],\n",
      "          [-0.0928,  0.0722, -0.0550],\n",
      "          [ 0.0826, -0.0323,  0.0778]],\n",
      "\n",
      "         [[-0.1057, -0.0687,  0.0415],\n",
      "          [ 0.0288, -0.0347,  0.0811],\n",
      "          [ 0.0925, -0.0987, -0.0727]],\n",
      "\n",
      "         [[ 0.1246, -0.0459, -0.0482],\n",
      "          [-0.1317, -0.0779,  0.0340],\n",
      "          [-0.0180, -0.0988,  0.0032]],\n",
      "\n",
      "         [[-0.0930, -0.1155, -0.0749],\n",
      "          [-0.1191, -0.0866,  0.1360],\n",
      "          [ 0.0257,  0.0419, -0.1269]]],\n",
      "\n",
      "\n",
      "        [[[-0.0894, -0.0453,  0.0213],\n",
      "          [-0.1197, -0.0586, -0.0815],\n",
      "          [ 0.0004, -0.0506, -0.0094]],\n",
      "\n",
      "         [[-0.0922, -0.0934, -0.0794],\n",
      "          [-0.0466, -0.1074,  0.1141],\n",
      "          [-0.0270,  0.1171,  0.0424]],\n",
      "\n",
      "         [[-0.1152,  0.0942, -0.0374],\n",
      "          [-0.0522, -0.1130, -0.1353],\n",
      "          [ 0.0389, -0.0297,  0.0530]],\n",
      "\n",
      "         [[-0.1117,  0.1010, -0.0999],\n",
      "          [-0.0235,  0.0284,  0.0703],\n",
      "          [ 0.1099,  0.1240, -0.1079]],\n",
      "\n",
      "         [[ 0.0342, -0.0585, -0.0149],\n",
      "          [-0.1019,  0.1240, -0.0999],\n",
      "          [ 0.0727,  0.0478,  0.0442]],\n",
      "\n",
      "         [[-0.0736,  0.1237,  0.0299],\n",
      "          [ 0.0175, -0.1199,  0.0571],\n",
      "          [-0.0204, -0.0623,  0.1169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303, -0.0753, -0.0689],\n",
      "          [-0.0065,  0.0760, -0.0348],\n",
      "          [-0.0776, -0.0466, -0.1017]],\n",
      "\n",
      "         [[ 0.0485,  0.1053, -0.1281],\n",
      "          [ 0.0316,  0.0703,  0.0247],\n",
      "          [-0.0485,  0.0710,  0.0715]],\n",
      "\n",
      "         [[ 0.0509, -0.0239, -0.0360],\n",
      "          [ 0.0146, -0.0240, -0.0406],\n",
      "          [ 0.0870,  0.1169, -0.0135]],\n",
      "\n",
      "         [[-0.0305,  0.0020, -0.0081],\n",
      "          [ 0.0327,  0.0381, -0.1236],\n",
      "          [-0.0502,  0.1146,  0.0530]],\n",
      "\n",
      "         [[-0.0068, -0.0820, -0.0833],\n",
      "          [-0.1219, -0.0444,  0.0460],\n",
      "          [ 0.0868,  0.0628, -0.1203]],\n",
      "\n",
      "         [[-0.0818, -0.0215,  0.1316],\n",
      "          [ 0.0197, -0.0352,  0.0563],\n",
      "          [-0.0518, -0.0881,  0.0993]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619, -0.0273, -0.1354],\n",
      "          [ 0.0911,  0.1031,  0.0496],\n",
      "          [-0.0949, -0.1343, -0.1105]],\n",
      "\n",
      "         [[ 0.1015,  0.0653,  0.1145],\n",
      "          [ 0.0713,  0.0344, -0.0013],\n",
      "          [-0.1035, -0.1166, -0.1273]],\n",
      "\n",
      "         [[ 0.0557, -0.0668, -0.0274],\n",
      "          [-0.0783, -0.0248, -0.0958],\n",
      "          [-0.0889,  0.0451, -0.0404]],\n",
      "\n",
      "         [[ 0.0840, -0.0437, -0.0998],\n",
      "          [-0.0240, -0.0660, -0.0416],\n",
      "          [-0.1296,  0.0761, -0.0947]],\n",
      "\n",
      "         [[ 0.0684,  0.0618,  0.0972],\n",
      "          [-0.1044,  0.0979, -0.0643],\n",
      "          [ 0.0505,  0.1278, -0.0192]],\n",
      "\n",
      "         [[-0.0011, -0.0313, -0.1136],\n",
      "          [ 0.0653, -0.1351,  0.0845],\n",
      "          [ 0.1018,  0.1287, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.1118,  0.0306,  0.0752],\n",
      "          [-0.1354, -0.0309, -0.0816],\n",
      "          [-0.0119, -0.0670, -0.0556]],\n",
      "\n",
      "         [[-0.0432, -0.1293,  0.1117],\n",
      "          [ 0.1141, -0.0213, -0.0155],\n",
      "          [-0.0555, -0.1229, -0.1324]],\n",
      "\n",
      "         [[ 0.0506, -0.0747, -0.0875],\n",
      "          [-0.0106, -0.0453, -0.0440],\n",
      "          [ 0.0044, -0.0289, -0.0469]],\n",
      "\n",
      "         [[-0.0652, -0.1107,  0.1141],\n",
      "          [-0.0545,  0.0361, -0.0472],\n",
      "          [ 0.0111,  0.1269,  0.0627]],\n",
      "\n",
      "         [[-0.1179,  0.0540,  0.1292],\n",
      "          [ 0.0358,  0.0912,  0.1342],\n",
      "          [-0.0209,  0.0282, -0.0946]],\n",
      "\n",
      "         [[-0.0280,  0.1008,  0.0698],\n",
      "          [-0.0861, -0.1091, -0.0930],\n",
      "          [-0.1343, -0.1050, -0.0337]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0918,  0.0228, -0.1035],\n",
      "          [-0.1092,  0.0677, -0.1012],\n",
      "          [-0.0168,  0.0653, -0.0630]],\n",
      "\n",
      "         [[-0.0148, -0.0118, -0.0322],\n",
      "          [-0.0690, -0.1213, -0.1100],\n",
      "          [-0.0729,  0.1314, -0.0657]],\n",
      "\n",
      "         [[-0.0914,  0.0330,  0.0375],\n",
      "          [ 0.0746,  0.1034,  0.0758],\n",
      "          [-0.1349,  0.0121,  0.0824]],\n",
      "\n",
      "         [[-0.0126, -0.0802,  0.1297],\n",
      "          [-0.0509, -0.0775, -0.1227],\n",
      "          [ 0.0061,  0.0603,  0.0301]],\n",
      "\n",
      "         [[ 0.0269, -0.1032, -0.1271],\n",
      "          [ 0.0024,  0.1241,  0.0785],\n",
      "          [-0.0792, -0.0177, -0.1003]],\n",
      "\n",
      "         [[-0.0656,  0.0246,  0.0741],\n",
      "          [ 0.1127, -0.1249,  0.0910],\n",
      "          [-0.0960,  0.0510,  0.1152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019,  0.1238, -0.1159],\n",
      "          [-0.0520,  0.0794, -0.0296],\n",
      "          [-0.0279, -0.0567,  0.0938]],\n",
      "\n",
      "         [[ 0.0667,  0.0436, -0.0765],\n",
      "          [-0.1105,  0.0147,  0.0403],\n",
      "          [-0.0628, -0.0381,  0.0919]],\n",
      "\n",
      "         [[ 0.0108,  0.0061, -0.0335],\n",
      "          [-0.1232, -0.1280, -0.0650],\n",
      "          [-0.0692,  0.0424, -0.0396]],\n",
      "\n",
      "         [[-0.0532,  0.1297,  0.0474],\n",
      "          [ 0.0970, -0.0659, -0.0556],\n",
      "          [ 0.0500, -0.0907, -0.0890]],\n",
      "\n",
      "         [[-0.0066, -0.0498, -0.1020],\n",
      "          [ 0.0807,  0.1094,  0.0221],\n",
      "          [-0.0237, -0.1260, -0.0496]],\n",
      "\n",
      "         [[ 0.0346,  0.0642, -0.0172],\n",
      "          [-0.0538,  0.0758, -0.1084],\n",
      "          [ 0.0860, -0.0528,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[-0.0269,  0.0165, -0.0411],\n",
      "          [ 0.0989, -0.0035,  0.1062],\n",
      "          [ 0.1308, -0.0663, -0.0993]],\n",
      "\n",
      "         [[ 0.1092,  0.1066, -0.1039],\n",
      "          [-0.0105, -0.1342, -0.1114],\n",
      "          [ 0.0263,  0.0362,  0.0288]],\n",
      "\n",
      "         [[-0.0370,  0.1255,  0.0195],\n",
      "          [-0.0803, -0.0077,  0.0327],\n",
      "          [ 0.0477, -0.0962,  0.0510]],\n",
      "\n",
      "         [[-0.0695, -0.1131, -0.0743],\n",
      "          [ 0.1312,  0.1163,  0.1219],\n",
      "          [ 0.0799,  0.1028, -0.0182]],\n",
      "\n",
      "         [[-0.0749,  0.0680, -0.0705],\n",
      "          [-0.0918, -0.0435,  0.0286],\n",
      "          [ 0.0701, -0.0529, -0.0801]],\n",
      "\n",
      "         [[ 0.0184, -0.0802, -0.0886],\n",
      "          [ 0.0709, -0.0229,  0.1244],\n",
      "          [ 0.1324,  0.0407,  0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0021, -0.0099],\n",
      "          [ 0.0019,  0.0508,  0.1265],\n",
      "          [-0.0353, -0.0575, -0.0330]],\n",
      "\n",
      "         [[-0.0657,  0.0231,  0.1016],\n",
      "          [ 0.1064,  0.0625, -0.1001],\n",
      "          [-0.0730, -0.0299, -0.0251]],\n",
      "\n",
      "         [[ 0.0112, -0.1249,  0.0424],\n",
      "          [-0.1038, -0.0861, -0.1131],\n",
      "          [ 0.1186, -0.1289,  0.1027]],\n",
      "\n",
      "         [[-0.0046, -0.0158,  0.0851],\n",
      "          [-0.0126,  0.0853,  0.0984],\n",
      "          [-0.1181,  0.0524,  0.0257]],\n",
      "\n",
      "         [[ 0.0293,  0.0199,  0.0372],\n",
      "          [-0.0655, -0.0174,  0.1293],\n",
      "          [ 0.0914, -0.0051, -0.1280]],\n",
      "\n",
      "         [[ 0.0060, -0.0927,  0.1107],\n",
      "          [-0.0826, -0.0098, -0.0302],\n",
      "          [ 0.0242,  0.1281,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0788,  0.1056,  0.1099],\n",
      "          [-0.0470, -0.0304,  0.0656],\n",
      "          [-0.0371,  0.0637, -0.0297]],\n",
      "\n",
      "         [[-0.0923,  0.0554,  0.0209],\n",
      "          [ 0.0607,  0.1352,  0.0929],\n",
      "          [ 0.1290,  0.0073, -0.1171]],\n",
      "\n",
      "         [[-0.0955, -0.0845, -0.1199],\n",
      "          [-0.0682, -0.1253, -0.1256],\n",
      "          [-0.0813, -0.1342, -0.0835]],\n",
      "\n",
      "         [[ 0.0519,  0.1135, -0.0405],\n",
      "          [-0.0396,  0.0727, -0.0671],\n",
      "          [-0.0643,  0.0838, -0.1186]],\n",
      "\n",
      "         [[ 0.0166,  0.1202,  0.0233],\n",
      "          [ 0.0370, -0.0793, -0.0019],\n",
      "          [ 0.0075,  0.0334,  0.0529]],\n",
      "\n",
      "         [[ 0.1182, -0.1039,  0.0041],\n",
      "          [-0.0680, -0.1077, -0.0109],\n",
      "          [-0.1198,  0.0950,  0.0158]]],\n",
      "\n",
      "\n",
      "        [[[-0.0733,  0.0711, -0.1288],\n",
      "          [-0.0526, -0.0265, -0.1156],\n",
      "          [-0.0865, -0.0222,  0.1033]],\n",
      "\n",
      "         [[ 0.1314,  0.0866, -0.0813],\n",
      "          [-0.0890,  0.1188,  0.0481],\n",
      "          [ 0.0036,  0.0184, -0.1094]],\n",
      "\n",
      "         [[-0.0454,  0.1310, -0.0336],\n",
      "          [-0.0068, -0.1130, -0.0761],\n",
      "          [-0.0028, -0.0845, -0.0169]],\n",
      "\n",
      "         [[ 0.0554, -0.1331,  0.0404],\n",
      "          [-0.0900, -0.0664,  0.0522],\n",
      "          [ 0.1082, -0.0372, -0.0559]],\n",
      "\n",
      "         [[-0.1231, -0.0702, -0.1192],\n",
      "          [-0.0311,  0.0278, -0.1275],\n",
      "          [ 0.1188,  0.0854, -0.1332]],\n",
      "\n",
      "         [[-0.0650,  0.0444, -0.0280],\n",
      "          [-0.0148, -0.0614,  0.1093],\n",
      "          [-0.0761,  0.1129,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274,  0.1062, -0.0224],\n",
      "          [-0.0775, -0.0220,  0.1104],\n",
      "          [-0.1010,  0.0309, -0.1337]],\n",
      "\n",
      "         [[ 0.0713,  0.0503,  0.0058],\n",
      "          [ 0.0584,  0.0002,  0.0753],\n",
      "          [-0.1077, -0.0200,  0.0604]],\n",
      "\n",
      "         [[ 0.1355,  0.0693, -0.0990],\n",
      "          [ 0.1047, -0.0303, -0.0291],\n",
      "          [-0.1237, -0.0214,  0.0963]],\n",
      "\n",
      "         [[ 0.0190, -0.0793,  0.0419],\n",
      "          [-0.0436,  0.1242, -0.1181],\n",
      "          [-0.0430, -0.1314, -0.0536]],\n",
      "\n",
      "         [[ 0.0429,  0.1310,  0.0229],\n",
      "          [ 0.1334,  0.0266,  0.0786],\n",
      "          [ 0.1091,  0.1138, -0.0762]],\n",
      "\n",
      "         [[ 0.1251,  0.0824, -0.0636],\n",
      "          [-0.0649, -0.1141,  0.0342],\n",
      "          [-0.1103,  0.0575,  0.0430]]],\n",
      "\n",
      "\n",
      "        [[[-0.1182,  0.0371, -0.0111],\n",
      "          [ 0.0622,  0.0781, -0.1353],\n",
      "          [ 0.1248,  0.1141,  0.0541]],\n",
      "\n",
      "         [[-0.1244, -0.0486, -0.0394],\n",
      "          [-0.0350,  0.0767,  0.0495],\n",
      "          [ 0.1078, -0.0510,  0.0458]],\n",
      "\n",
      "         [[ 0.0484, -0.1133, -0.1320],\n",
      "          [-0.0706,  0.0932, -0.1281],\n",
      "          [-0.1185,  0.0762,  0.0734]],\n",
      "\n",
      "         [[ 0.1119, -0.1027, -0.0996],\n",
      "          [ 0.0698,  0.1183,  0.0814],\n",
      "          [ 0.0213,  0.0448,  0.1292]],\n",
      "\n",
      "         [[-0.0878, -0.0618,  0.0952],\n",
      "          [-0.0931, -0.0750,  0.0993],\n",
      "          [ 0.0429,  0.0440, -0.0577]],\n",
      "\n",
      "         [[-0.0019,  0.1245, -0.0817],\n",
      "          [ 0.0011,  0.0647, -0.0939],\n",
      "          [ 0.1322, -0.0680, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.0368, -0.0887, -0.1335],\n",
      "          [ 0.0767,  0.0362, -0.1275],\n",
      "          [-0.0876,  0.1345,  0.0520]],\n",
      "\n",
      "         [[ 0.0546, -0.0814, -0.0597],\n",
      "          [-0.0205, -0.0249, -0.0933],\n",
      "          [ 0.0112,  0.0135, -0.0172]],\n",
      "\n",
      "         [[ 0.0189, -0.0539,  0.0354],\n",
      "          [ 0.0513, -0.0717, -0.1349],\n",
      "          [ 0.0712,  0.0325, -0.0692]],\n",
      "\n",
      "         [[ 0.1311, -0.0615,  0.0920],\n",
      "          [ 0.0690, -0.1141,  0.0878],\n",
      "          [-0.1251, -0.0754, -0.0227]],\n",
      "\n",
      "         [[-0.0917,  0.1329, -0.0273],\n",
      "          [ 0.0541, -0.1215,  0.0783],\n",
      "          [-0.0423, -0.1035,  0.0199]],\n",
      "\n",
      "         [[ 0.0659,  0.1178, -0.0831],\n",
      "          [-0.0670,  0.0262,  0.0369],\n",
      "          [ 0.0523,  0.0747, -0.0309]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0756,  0.1003, -0.0355],\n",
      "          [ 0.0968,  0.0665,  0.1200],\n",
      "          [-0.0773, -0.0672, -0.0393]],\n",
      "\n",
      "         [[ 0.0069,  0.0817, -0.0777],\n",
      "          [ 0.0681, -0.0488,  0.0822],\n",
      "          [-0.0065, -0.1192, -0.0749]],\n",
      "\n",
      "         [[-0.0985,  0.0675, -0.0913],\n",
      "          [-0.0113,  0.0294, -0.0746],\n",
      "          [ 0.0393, -0.1329, -0.0974]],\n",
      "\n",
      "         [[-0.1233, -0.0412, -0.0496],\n",
      "          [ 0.0195, -0.0252,  0.0640],\n",
      "          [ 0.1248,  0.0488, -0.0536]],\n",
      "\n",
      "         [[-0.1274,  0.0493, -0.0674],\n",
      "          [ 0.0692,  0.0910,  0.0525],\n",
      "          [ 0.1277,  0.1293,  0.0288]],\n",
      "\n",
      "         [[-0.0992,  0.1216, -0.0646],\n",
      "          [-0.0643,  0.1139,  0.1054],\n",
      "          [ 0.0411,  0.0085, -0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141,  0.1305,  0.0347],\n",
      "          [ 0.0117, -0.0283, -0.0475],\n",
      "          [ 0.0811,  0.0084,  0.0885]],\n",
      "\n",
      "         [[-0.0241,  0.0595,  0.0562],\n",
      "          [ 0.0217,  0.0855,  0.0853],\n",
      "          [ 0.1261,  0.1046, -0.0348]],\n",
      "\n",
      "         [[-0.1152,  0.0249, -0.0012],\n",
      "          [-0.0355, -0.0228,  0.0064],\n",
      "          [ 0.0993,  0.0424, -0.0483]],\n",
      "\n",
      "         [[-0.0560, -0.0337, -0.0526],\n",
      "          [ 0.1224,  0.0721,  0.1229],\n",
      "          [ 0.0004,  0.0274,  0.0472]],\n",
      "\n",
      "         [[-0.1288,  0.0122, -0.0091],\n",
      "          [-0.0763, -0.1056,  0.1205],\n",
      "          [ 0.1106,  0.0631,  0.1299]],\n",
      "\n",
      "         [[-0.0552, -0.0235,  0.0515],\n",
      "          [-0.0225, -0.0267, -0.1125],\n",
      "          [ 0.0366, -0.0822,  0.0049]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1327, -0.0419, -0.0429,  0.0821, -0.0500, -0.0117,  0.1271, -0.0558,\n",
      "        -0.0974, -0.0762, -0.0377, -0.0646, -0.0706,  0.0550,  0.0231, -0.0436],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.8846e-02, -1.5743e-02, -2.1102e-02,  ..., -7.6693e-05,\n",
      "          4.8436e-02, -1.9859e-02],\n",
      "        [-1.1636e-02, -2.5271e-02,  7.1948e-03,  ..., -1.7114e-02,\n",
      "         -2.9444e-02,  3.3103e-02],\n",
      "        [ 6.7186e-03,  2.0927e-02, -1.8936e-02,  ..., -4.6726e-02,\n",
      "          3.3182e-03, -1.7761e-02],\n",
      "        ...,\n",
      "        [-4.3866e-02,  3.7438e-02, -4.2277e-02,  ...,  4.5558e-02,\n",
      "          2.3612e-02, -4.4892e-02],\n",
      "        [ 1.6117e-02,  1.6008e-02,  2.6415e-02,  ..., -3.6400e-02,\n",
      "          1.4238e-02,  3.9001e-02],\n",
      "        [-1.7557e-02, -2.1580e-02,  4.0183e-02,  ...,  5.0929e-03,\n",
      "          4.3303e-02, -4.1396e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0400, -0.0132, -0.0299, -0.0310,  0.0312,  0.0441,  0.0343, -0.0473,\n",
      "        -0.0008,  0.0072,  0.0363, -0.0249, -0.0220, -0.0055, -0.0091,  0.0066,\n",
      "        -0.0191, -0.0118, -0.0330,  0.0443, -0.0144, -0.0258, -0.0401, -0.0316,\n",
      "         0.0284,  0.0334,  0.0075, -0.0444, -0.0477, -0.0182, -0.0170, -0.0190,\n",
      "        -0.0163, -0.0279, -0.0349,  0.0035, -0.0400, -0.0317, -0.0016,  0.0015,\n",
      "         0.0436, -0.0034,  0.0314, -0.0055,  0.0237, -0.0089,  0.0256,  0.0277,\n",
      "        -0.0481,  0.0012,  0.0010,  0.0096, -0.0472, -0.0495, -0.0400, -0.0047,\n",
      "         0.0345, -0.0277, -0.0216, -0.0290,  0.0261,  0.0368,  0.0033,  0.0269,\n",
      "         0.0461, -0.0069, -0.0212, -0.0286,  0.0359,  0.0303, -0.0336,  0.0286,\n",
      "         0.0226,  0.0231,  0.0172, -0.0077,  0.0228, -0.0317, -0.0057,  0.0200,\n",
      "         0.0196, -0.0247, -0.0427,  0.0248, -0.0250,  0.0274, -0.0473, -0.0432,\n",
      "         0.0465,  0.0449, -0.0165,  0.0297,  0.0328, -0.0133,  0.0391,  0.0355,\n",
      "         0.0485, -0.0063, -0.0442, -0.0260, -0.0080, -0.0207,  0.0316,  0.0417,\n",
      "         0.0384,  0.0112, -0.0234, -0.0303, -0.0059, -0.0286,  0.0399, -0.0384,\n",
      "        -0.0390, -0.0290, -0.0329, -0.0307,  0.0183, -0.0207, -0.0320,  0.0365],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0371,  0.0817,  0.0687,  ..., -0.0570,  0.0406, -0.0083],\n",
      "        [ 0.0591, -0.0907, -0.0863,  ..., -0.0754,  0.0787, -0.0542],\n",
      "        [-0.0385, -0.0518,  0.0064,  ...,  0.0870,  0.0634, -0.0167],\n",
      "        ...,\n",
      "        [-0.0752,  0.0148, -0.0138,  ...,  0.0169,  0.0578, -0.0175],\n",
      "        [ 0.0579, -0.0846, -0.0538,  ..., -0.0163,  0.0133,  0.0372],\n",
      "        [-0.0691, -0.0808,  0.0382,  ..., -0.0006, -0.0693, -0.0764]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0058,  0.0849,  0.0859, -0.0189,  0.0273, -0.0852, -0.0591,  0.0678,\n",
      "         0.0148,  0.0224,  0.0103, -0.0367,  0.0740,  0.0870,  0.0377,  0.0854,\n",
      "         0.0274,  0.0690, -0.0584,  0.0318, -0.0649, -0.0117, -0.0593,  0.0311,\n",
      "        -0.0852, -0.0268, -0.0367,  0.0592, -0.0653, -0.0452,  0.0764,  0.0387,\n",
      "         0.0709,  0.0839, -0.0556,  0.0249, -0.0682, -0.0311, -0.0149, -0.0454,\n",
      "         0.0190,  0.0133,  0.0189,  0.0501, -0.0112,  0.0732, -0.0066,  0.0625,\n",
      "         0.0711,  0.0843, -0.0440, -0.0322, -0.0702, -0.0380,  0.0840, -0.0104,\n",
      "        -0.0479, -0.0699, -0.0730, -0.0506,  0.0307, -0.0485, -0.0318, -0.0764,\n",
      "        -0.0815, -0.0529, -0.0844, -0.0059, -0.0318, -0.0430, -0.0552,  0.0333,\n",
      "         0.0385, -0.0173,  0.0355,  0.0825, -0.0293, -0.0550,  0.0566, -0.0207,\n",
      "        -0.0371,  0.0593,  0.0267, -0.0664], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0248,  0.0496,  0.1048, -0.0526,  0.0552, -0.0156,  0.0163, -0.1028,\n",
      "         -0.0987,  0.0589,  0.0010,  0.0489, -0.0655,  0.0836, -0.0392, -0.0669,\n",
      "          0.0943, -0.0640, -0.0646, -0.0934,  0.0483, -0.0124, -0.0031,  0.0337,\n",
      "         -0.0306,  0.0181, -0.0586, -0.0257,  0.0614,  0.0329,  0.0728,  0.1024,\n",
      "          0.0769, -0.0391, -0.0918, -0.0467, -0.0079,  0.1040,  0.0128, -0.0154,\n",
      "          0.0767,  0.0438,  0.0905,  0.0158, -0.0073,  0.0525, -0.0067, -0.0647,\n",
      "         -0.0306, -0.0497, -0.0082,  0.0735,  0.0210, -0.0641, -0.0340, -0.0675,\n",
      "         -0.0203, -0.0563,  0.0341, -0.0174, -0.0606,  0.0495,  0.0197,  0.0262,\n",
      "          0.0665,  0.0555, -0.0718,  0.0611, -0.0739, -0.0849,  0.1066, -0.0612,\n",
      "          0.0044,  0.0641, -0.0631, -0.0488,  0.0129, -0.0111,  0.0599,  0.0168,\n",
      "         -0.0014,  0.0162,  0.1045, -0.0783],\n",
      "        [ 0.0882,  0.0137,  0.0816,  0.0278, -0.0595,  0.1075,  0.0605, -0.0945,\n",
      "          0.0949,  0.0850,  0.0864,  0.0311,  0.0391, -0.0184,  0.0773, -0.0719,\n",
      "          0.0261,  0.0701, -0.0290,  0.0690,  0.0600,  0.0104,  0.0042, -0.0508,\n",
      "         -0.0048, -0.1056,  0.0545,  0.0531,  0.0336, -0.0486, -0.0944, -0.0654,\n",
      "          0.0298, -0.0882,  0.0780,  0.1033,  0.0648, -0.0341,  0.0122, -0.0119,\n",
      "          0.0177,  0.0067,  0.0830,  0.0863,  0.0869,  0.0604,  0.0682,  0.0734,\n",
      "          0.0846,  0.0437, -0.0695,  0.0976,  0.0220, -0.0659, -0.0099,  0.0403,\n",
      "         -0.0889, -0.0849, -0.0445,  0.0882,  0.0410,  0.0559,  0.0465,  0.0951,\n",
      "          0.0974,  0.1018,  0.0684,  0.0532,  0.0421,  0.0886, -0.1047,  0.0518,\n",
      "          0.1065,  0.0381,  0.0025, -0.0355,  0.0278, -0.0517,  0.0392, -0.0233,\n",
      "          0.0412, -0.0689, -0.0730, -0.0889],\n",
      "        [ 0.0211,  0.0628,  0.0693, -0.0847,  0.0383,  0.0297,  0.0693, -0.0705,\n",
      "         -0.0365, -0.0748,  0.0076, -0.0852,  0.0821, -0.0947,  0.0081,  0.0159,\n",
      "         -0.0058, -0.0768,  0.0460,  0.0884,  0.0024,  0.0706, -0.0973, -0.0135,\n",
      "         -0.0169,  0.0932,  0.0269, -0.0902,  0.0224,  0.0129,  0.0112,  0.0595,\n",
      "          0.0545, -0.0263,  0.0419, -0.0140, -0.0723,  0.0820,  0.0403,  0.0803,\n",
      "         -0.0726,  0.0017, -0.0765, -0.0334,  0.0872, -0.0266,  0.0411,  0.0467,\n",
      "         -0.0758,  0.0754, -0.0838,  0.0873, -0.0258, -0.1054,  0.0052,  0.1044,\n",
      "          0.0385, -0.0294,  0.0247,  0.0435, -0.0972, -0.0924, -0.0883,  0.0991,\n",
      "         -0.0663, -0.0510,  0.0565, -0.0589,  0.0159,  0.0703,  0.0290,  0.0007,\n",
      "         -0.0742, -0.0620, -0.0272,  0.1014,  0.0284,  0.0358,  0.0107,  0.0040,\n",
      "          0.0957,  0.0221,  0.0344,  0.0343],\n",
      "        [ 0.0592,  0.1049, -0.0349, -0.0202,  0.0299,  0.0612,  0.1015, -0.0460,\n",
      "          0.0150,  0.0656,  0.0492,  0.0954,  0.0042, -0.0902,  0.0111, -0.0616,\n",
      "          0.0120, -0.0602, -0.0323, -0.0048, -0.0279, -0.0516,  0.0482, -0.0748,\n",
      "          0.0679, -0.0312,  0.0778, -0.0607,  0.0754,  0.0605,  0.0722, -0.1035,\n",
      "         -0.0362, -0.0975, -0.1060, -0.0828,  0.0828, -0.0497, -0.0539, -0.0125,\n",
      "          0.0375, -0.0029, -0.0727,  0.0555,  0.0570,  0.0795,  0.0531,  0.0637,\n",
      "          0.0572,  0.0589,  0.1058, -0.0806,  0.0813, -0.0870, -0.0609, -0.0027,\n",
      "          0.0824, -0.0554,  0.0745, -0.0768, -0.0549,  0.0557,  0.0213, -0.0224,\n",
      "         -0.0928,  0.0730, -0.0739,  0.0719,  0.0562, -0.0152, -0.0026, -0.1034,\n",
      "          0.0232,  0.0055, -0.0531, -0.0987,  0.0396,  0.0292,  0.0619, -0.0272,\n",
      "         -0.1031, -0.0822, -0.0343,  0.0954],\n",
      "        [ 0.0040, -0.0493,  0.0212,  0.0647,  0.0705, -0.0557,  0.0793, -0.0454,\n",
      "         -0.0629, -0.0621, -0.0586,  0.0254,  0.0817,  0.0240, -0.0413,  0.0237,\n",
      "          0.1013, -0.0606, -0.0019, -0.0351,  0.0570, -0.0371, -0.0011, -0.0276,\n",
      "         -0.1048, -0.0766, -0.0335, -0.0390, -0.0980,  0.0408, -0.0779, -0.0918,\n",
      "          0.0603, -0.0652,  0.0758,  0.0123, -0.0990,  0.1045, -0.0989, -0.1033,\n",
      "         -0.0964,  0.0613, -0.1038, -0.0192,  0.0830, -0.0264,  0.0930, -0.0911,\n",
      "          0.0578, -0.0445, -0.0826,  0.0561, -0.0509, -0.0954,  0.0651, -0.0931,\n",
      "         -0.0746, -0.0657,  0.0456,  0.0280, -0.0925, -0.1074, -0.0916,  0.0258,\n",
      "         -0.0556, -0.0061,  0.0757, -0.0800,  0.0007, -0.0619,  0.0133,  0.1062,\n",
      "         -0.0659,  0.0780,  0.0803,  0.0844,  0.0086,  0.0840,  0.0899, -0.0879,\n",
      "         -0.0358, -0.0232,  0.0621, -0.0447],\n",
      "        [ 0.0359,  0.0852,  0.1054,  0.0382,  0.0210, -0.0368,  0.0491, -0.0443,\n",
      "          0.0771, -0.0022, -0.0886,  0.0879, -0.0399,  0.0714, -0.0201,  0.1035,\n",
      "          0.1042,  0.0694, -0.0221,  0.0005, -0.0487,  0.0003,  0.0991,  0.0182,\n",
      "          0.0800, -0.0938,  0.0539, -0.0963,  0.0380, -0.1066, -0.0198, -0.0787,\n",
      "         -0.0558,  0.1086, -0.0277,  0.0586, -0.0358, -0.0492, -0.1051, -0.0162,\n",
      "          0.1058, -0.0468, -0.0245, -0.0906, -0.1037,  0.1050,  0.0538, -0.0845,\n",
      "          0.0806, -0.0374,  0.0376, -0.0050,  0.0191, -0.1032, -0.0361, -0.0882,\n",
      "          0.1031,  0.0382,  0.0413,  0.0600, -0.0701,  0.0848,  0.0677,  0.0486,\n",
      "          0.1051,  0.0244, -0.0405,  0.0713, -0.0040, -0.0774, -0.0025, -0.0208,\n",
      "         -0.0905, -0.0729,  0.0716, -0.0087,  0.0324, -0.0742, -0.0241,  0.0251,\n",
      "          0.1058, -0.0039,  0.0158, -0.1049],\n",
      "        [-0.0628, -0.0878,  0.0763,  0.0617,  0.0888, -0.0173,  0.0895,  0.0249,\n",
      "          0.0028,  0.0626,  0.0481,  0.0865,  0.0291, -0.0398,  0.0417,  0.0020,\n",
      "          0.0213,  0.0773,  0.0729, -0.0516,  0.0983,  0.0902, -0.0495,  0.0275,\n",
      "         -0.0764, -0.0047, -0.0669,  0.1046, -0.1020, -0.0022, -0.0765, -0.0040,\n",
      "         -0.1071, -0.0907,  0.0941, -0.0012,  0.0884, -0.0856, -0.0452,  0.1071,\n",
      "         -0.0486, -0.0602,  0.0889, -0.0834,  0.0450, -0.0998,  0.0317,  0.0055,\n",
      "         -0.1032,  0.0982, -0.0634, -0.0558,  0.1079, -0.0984, -0.0051,  0.0962,\n",
      "         -0.0767, -0.0544, -0.0041, -0.0942,  0.1025, -0.0020, -0.0915, -0.0235,\n",
      "         -0.0664,  0.0918,  0.0847,  0.0366, -0.0087,  0.1066,  0.0862,  0.0393,\n",
      "         -0.0934, -0.0306, -0.0805,  0.0355,  0.0673,  0.0745, -0.0246, -0.0379,\n",
      "          0.0593,  0.0546,  0.1086, -0.0660],\n",
      "        [ 0.1021, -0.0642,  0.0284, -0.0675, -0.1070,  0.0793,  0.0111,  0.0355,\n",
      "         -0.0357, -0.0184, -0.0397, -0.0551,  0.0942, -0.0625, -0.0048, -0.0386,\n",
      "         -0.1089,  0.0570,  0.1077, -0.0330, -0.0978,  0.0119, -0.0699, -0.0238,\n",
      "         -0.0631, -0.0103,  0.0035, -0.0923, -0.0942, -0.0357,  0.0766, -0.0189,\n",
      "         -0.0281, -0.0299, -0.0730, -0.0560, -0.0871, -0.1007,  0.0981, -0.0694,\n",
      "         -0.0293,  0.0322, -0.0315,  0.0487,  0.0935,  0.0130,  0.0965, -0.0375,\n",
      "         -0.0071, -0.0246,  0.0337, -0.0683,  0.1067,  0.0162, -0.0884,  0.1023,\n",
      "         -0.0524,  0.0434, -0.0031, -0.0372, -0.0488, -0.0936,  0.0193,  0.0174,\n",
      "          0.1028,  0.0344, -0.0675,  0.0182,  0.0852,  0.0666,  0.0953, -0.0364,\n",
      "          0.0892,  0.0258,  0.0221, -0.0710, -0.0403,  0.0120, -0.1073,  0.0456,\n",
      "         -0.0709, -0.0186, -0.0657,  0.0840],\n",
      "        [-0.0155,  0.0614,  0.0309,  0.0086, -0.0071,  0.0882, -0.0411,  0.0810,\n",
      "          0.1007, -0.0145, -0.0551,  0.0885, -0.0476,  0.0442, -0.0037, -0.0530,\n",
      "          0.0212,  0.0731, -0.0790, -0.0987, -0.0694, -0.0940, -0.1004,  0.0321,\n",
      "          0.0711, -0.1020,  0.0809,  0.0850, -0.0105, -0.0428,  0.0824,  0.0646,\n",
      "         -0.0827, -0.0709,  0.0913,  0.0088, -0.0296, -0.0325,  0.1031, -0.0141,\n",
      "          0.0949,  0.0054, -0.0139, -0.0252,  0.0315,  0.0637,  0.0267,  0.0253,\n",
      "         -0.0564, -0.0872, -0.0508,  0.0945,  0.0975,  0.0177,  0.0940, -0.0738,\n",
      "         -0.0525, -0.0044, -0.0806,  0.0858, -0.0377, -0.0672,  0.1069, -0.0107,\n",
      "         -0.0811,  0.0484, -0.0447, -0.0863, -0.0419,  0.0482, -0.0742,  0.0693,\n",
      "          0.0164, -0.0786,  0.0160, -0.0936,  0.0943, -0.1089, -0.0686,  0.0901,\n",
      "         -0.0554, -0.0398,  0.0504,  0.0972],\n",
      "        [ 0.0186, -0.0742,  0.0939, -0.0619,  0.0032, -0.0398,  0.0144,  0.0391,\n",
      "          0.0971, -0.1045,  0.0616, -0.0703, -0.0124,  0.0156,  0.1049, -0.1022,\n",
      "          0.0343, -0.1026,  0.0860,  0.0336, -0.0295, -0.0593,  0.0172,  0.0724,\n",
      "          0.0898,  0.0321, -0.0963, -0.0986, -0.0019,  0.0379, -0.0537,  0.0474,\n",
      "         -0.0339,  0.0696, -0.0688,  0.0789,  0.0768, -0.0309,  0.0261,  0.0124,\n",
      "         -0.0040, -0.0936, -0.0479, -0.0150, -0.0706, -0.0253, -0.1053,  0.0656,\n",
      "          0.0729,  0.0296,  0.0949, -0.0721,  0.0266, -0.0155, -0.0430,  0.0036,\n",
      "         -0.0411, -0.0384,  0.0130, -0.0367,  0.0120, -0.0739,  0.0287, -0.0913,\n",
      "          0.0911,  0.1081,  0.0193,  0.0790, -0.0005, -0.0344,  0.0530,  0.0209,\n",
      "          0.0620, -0.0369,  0.1019,  0.0579, -0.1069,  0.0029,  0.0717, -0.0314,\n",
      "          0.0436,  0.0081, -0.0750, -0.0623]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0363, -0.1061,  0.0859,  0.0742, -0.0242, -0.0972,  0.0560, -0.0302,\n",
      "         0.0280, -0.0756], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "This time we'll feed the data directly into the model without flattening it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.61011904  accuracy:  78.650%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.03751423  accuracy:  85.525%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.24703658  accuracy:  88.722%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.00395802  accuracy:  90.525%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.47399369  accuracy:  91.677%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.00279189  accuracy:  92.564%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.05014556  accuracy:  93.200%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.01009761  accuracy:  93.677%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.00428647  accuracy:  97.300%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.02088502  accuracy:  97.367%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.05341913  accuracy:  97.422%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00315051  accuracy:  97.600%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00257667  accuracy:  97.693%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.00279047  accuracy:  97.772%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.00032113  accuracy:  97.798%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.07803176  accuracy:  97.812%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.15571532  accuracy:  98.300%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00068152  accuracy:  98.400%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00025755  accuracy:  98.422%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.00037929  accuracy:  98.412%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.00181280  accuracy:  98.390%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00181656  accuracy:  98.431%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.04618856  accuracy:  98.419%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00525408  accuracy:  98.421%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.00308421  accuracy:  99.017%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.02881540  accuracy:  99.133%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.01799211  accuracy:  98.961%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.13697107  accuracy:  98.842%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.01102370  accuracy:  98.847%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.00001933  accuracy:  98.850%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00162646  accuracy:  98.871%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.31762365  accuracy:  98.825%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00174027  accuracy:  99.317%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.01792913  accuracy:  99.167%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00002938  accuracy:  99.206%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00064868  accuracy:  99.121%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.00554380  accuracy:  99.090%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.01450366  accuracy:  99.011%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.17181352  accuracy:  99.002%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00005393  accuracy:  98.987%\n",
      "\n",
      "Duration: 107 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_correct = []\n",
    "val_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the validation batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_val, y_val) in enumerate(val_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            yhat_val = model(X_val)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(yhat_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_val).sum()\n",
    "            \n",
    "    loss = criterion(yhat_val, y_val)\n",
    "    val_losses.append(loss)\n",
    "    val_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [loss.item() for loss in train_losses]\n",
    "val_losses   = [loss.item() for loss in val_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006417757831513882,\n",
       " 0.12822018563747406,\n",
       " 0.0017054991330951452,\n",
       " 0.017299529165029526,\n",
       " 0.00046517682494595647]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5892243385314941,\n",
       " 0.03484190255403519,\n",
       " 0.0008685365319252014,\n",
       " 0.0031729943584650755,\n",
       " 0.000636119453702122]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may be some overfitting of the training data, there is far less than we saw with the ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in val_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46923)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(93.846, dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 100*train_correct[0]/(len(train_loader)*10)\n",
    "temp.numpy() # converts tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9861/10000 =  98.610%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our [784,120,84,10] ANN returned an accuracy of 97.25% after 10 epochs. And it used 105,214 parameters to our current 60,074."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 975    2    0    0    0    1    3    0    3    0]\n",
      " [   0 1129    0    0    1    0    5    5    1    1]\n",
      " [   1    1 1029    3    1    0    1    7    3    0]\n",
      " [   0    1    0 1002    0   12    0    1    4    4]\n",
      " [   0    0    0    0  964    0    7    0    0    2]\n",
      " [   0    0    0    3    0  870    3    0    0    5]\n",
      " [   1    0    0    0    1    1  935    0    0    0]\n",
      " [   1    1    2    2    1    0    0 1008    0    0]\n",
      " [   2    1    1    0    4    4    4    2  962   10]\n",
      " [   0    0    0    0   10    4    0    5    1  987]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 184,  247,  320,  339,  340,  412,  445,  448,  449,  740])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x142543460>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [ 184  247  320  339  340  412  445  448  449  740  813  829]\n",
      "Label: [   8    4    9    6    5    5    6    9    3    4    9    4]\n",
      "Guess: [   3    2    8    5    3    3    0    8    5    9    8    8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a new image through the model\n",
    "We can also pass a single image through the model to obtain a prediction.\n",
    "Pick a number from 0 to 9999, assign it to \"x\", and we'll use that value to select a number from the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 2019\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(test_data[x][0].reshape((28,28)), cmap=\"gist_yarg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())\n",
    "# model.eval() vs torch.no_grad()\n",
    "# https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
